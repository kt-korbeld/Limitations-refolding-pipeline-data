import os
from tqdm import tqdm

# analysis
import numpy as np
import pandas as pd
from sklearn import metrics
from scipy.stats import fisher_exact

# plotting
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.patches import Rectangle

import warnings
warnings.filterwarnings("ignore", message="^.*set_ticklabels().*$")

# ==============================
# Fig 2 — Scramble experiment
# ==============================

def add_designability_scrambled(agg_df:pd.DataFrame, scrmsd_cutoff:int=2.0, plddt_cutoff:int=70, tm_cutoff:int=0.5):
    '''
    Fig 2
    for a dataframe with pLDDT, scRMSD and scTM values, add column for if designabilty cutoffs are met:
    just scRMSD (scrmsd_des), scRMSD and pLDDT (plddt_des), and scTM and pLDDT (tm_des)
    '''
    upd_df = agg_df.copy()
    for i, row in tqdm(agg_df.iterrows()):
        scrmsd = row['sc_rmsd']
        plddt = row['plddt']
        tm_score = row['tm_score']
        # just scRMSD
        if scrmsd <= scrmsd_cutoff:
            upd_df.loc[i, 'scrmsd_des'] = True
        else:
            upd_df.loc[i, 'scrmsd_des'] = False
        # scRMSD and pLDDT
        if scrmsd <= scrmsd_cutoff and plddt >= plddt_cutoff:
            upd_df.loc[i, 'plddt_des'] = True
        else:
            upd_df.loc[i, 'plddt_des'] = False
        # scTM and pLDDT  
        if tm_score >= tm_cutoff and plddt >= plddt_cutoff:
            upd_df.loc[i, 'tm_des'] = True
        else:
            upd_df.loc[i, 'tm_des'] = False
            
    return upd_df

def make_des_for_diff_plddt(df:pd.DataFrame, plddt_list:list[int]=[70, 80, 85]):
    '''
    Fig 2
    generate a nested list of dataframes with designability for different sets of cutoffs
    '''
    dfs_list = []
    for plddt in plddt_list:
        df = add_designability_scrambled(df,scrmsd_cutoff=2.0, plddt_cutoff=plddt,tm_cutoff=0.5)
        df = rename_header_to_native(df)
        dfs_list.append(df)
    return dfs_list

def rename_header_to_native(df:pd.DataFrame):
    '''
    Fig 2
    rename header to native
    '''
    df['header'] = df['header'].apply(
        lambda x: 'native' if not (x.startswith('sample') or x.startswith('scrambled')) else x)
    return df

def lineplot_des_plddt_as_3(list_dfs: list[list[pd.DataFrame]], folder_outputs: str, 
                            output_name: str, label_models: list,
                            fontsize_label:int=30, fontsize_ticks:int=28, palette: list=[]):
    '''
    Fig 2
    for a nested list of dataframes with different models and pLDDT cutoffs
    generated by make_des_for_diff_plddt, plot the designability as a function of time. 
    '''
    fig, axs = plt.subplots(1, 3, figsize=(25, 7))
    labels = ['pLDDT 70', 'pLDDT 80', 'pLDDT 85']
    # enumerate over each df and plot designability over scramble percentage
    for model_idx, model_dfs in enumerate(list_dfs):
        # enumerate over different pLDDT cutoffs
        for i, label in enumerate(labels):
            agg_df = model_dfs[i]
            # select unscrambled sequences
            natives = agg_df[agg_df['header'] == 'native']
            scr_natives = np.repeat('0.0', len(natives))
            des_natives = natives['plddt_des'].values
            # select scrambled sequences, sort by scramble percent
            agg_df_filtered = agg_df[agg_df['header'] != 'native']
            agg_sorted = agg_df_filtered.sort_values(by='scr_pctg')
            scr_pctgs = agg_sorted['scr_pctg'].astype(str).values
            des_scrambled = agg_sorted['plddt_des'].values
            # plot change in designability as function of scramble percent
            scr_pctgs = np.concatenate([scr_natives, scr_pctgs])
            des_vals = np.concatenate([des_natives, des_scrambled])
            plot_df = pd.DataFrame({'scr_pctg': scr_pctgs,'des': des_vals,'model': f'model_{model_idx + 1}'})
            sns.lineplot(data=plot_df, x='scr_pctg', y='des', ax=axs[i], marker='o', label=label_models[model_idx],
                         linewidth=3, markersize=10, color=palette[model_idx], alpha=1)
    # format final figure
    xticks = [str(i.split('_')[-1]) for i in agg_sorted['scr_pctg'].astype(str) if i != 'native']
    xticks = sorted(list(set(xticks)))
    xticks.insert(0, '0.0')
    for i, label in enumerate(labels):
        axs[i].set_xticklabels(xticks, rotation=0)
        axs[i].tick_params(axis='both', which='major', labelsize=fontsize_ticks)
        axs[i].set_xlabel('Fraction of mutated residues', labelpad=10, fontsize=fontsize_label)
        axs[i].set_title(f'{label}', fontsize=fontsize_label)
        axs[i].set_ylabel('', labelpad=0, fontsize=5)
        axs[i].legend('', frameon=False)
        if i == 0:
            axs[i].set_ylabel('Designability', labelpad=10, fontsize=fontsize_label)
        if i == 2:
            axs[i].legend(frameon=False, fontsize=24)
    sns.despine()   
    # increase the white box around the plots
    plt.tight_layout()
    # plt.subplots_adjust(wspace=0.4)
    plt.savefig(os.path.join(folder_outputs, output_name), dpi=300, bbox_inches='tight')
    plt.show()

# ==============================
# Fig 3 — Experimental benchmark
# ==============================

def compute_roc_metrics(true_vals, vals_in):
    '''
    Fig 3
    compute ROC AUC for a given list of binary ground truth values and predicted values.
    '''
    fpr, tpr, thresholds = metrics.roc_curve(true_vals, vals_in)
    auc_roc = round(metrics.auc(fpr, tpr), 2)
    return auc_roc

def make_df_barplot(roc_plddt:list, roc_rmsd:list, nr:int, name:str, esmf:bool=True):
    '''
    Fig 3
    prepare pandas df for barplot figure with experimental data
    '''
    if esmf:
        df = pd.DataFrame({
            'annot': ['AF2 ss', 'ESMFold', 'AF2 MSA'],
            'AUC pLDDT': [roc_plddt[0], roc_plddt[1], roc_plddt[2]],
            'AUC scRMSD': [roc_rmsd[0], roc_rmsd[1], roc_rmsd[2]],
            'name':[name, name, name],
            'count':[nr, nr, nr]})
    else:
        df = pd.DataFrame({
            'annot': ['AF2 ss', 'AF2 MSA'],
            'AUC pLDDT': [roc_plddt[0], roc_plddt[2]],
            'AUC scRMSD': [roc_rmsd[0], roc_rmsd[2]],
            'name':[name, name],
            'count':[nr, nr]})        
    return df

def add_weighted_avg(df_in):
    '''
    Fig 3
    add weighted average of ROC AUC to dataframe
    '''
    # calculate weighted average
    roc_plddt_combined, roc_rmsd_combined, counts = [], [], []
    for i in ['AF2 ss', 'ESMFold', 'AF2 MSA']:
        df_sel = df_in[df_in.annot == i]
        roc_plddt_combined.append((df_sel['AUC pLDDT']*df_sel['count']).sum() / df_sel['count'].sum())
        roc_rmsd_combined.append((df_sel['AUC scRMSD']*df_sel['count']).sum() / df_sel['count'].sum())
        counts.append(df_sel['count'].sum())
    df_avg = pd.DataFrame({'annot':['AF2 ss', 'ESMFold', 'AF2 MSA'], 'AUC pLDDT':roc_plddt_combined, 'AUC scRMSD':roc_rmsd_combined,
                           'name':3*['Total'], 'count':counts})
    return pd.concat([df_in, df_avg], ignore_index=True)


def aggregate_df_barplot(dfs_dataset:pd.DataFrame, dataset_order:list, df_exp:pd.DataFrame):
    '''
    Fig 3
    aggregate different datasets into one df with ROC AUCs for each
    '''
    dfs_roc = []
    for dataset in dataset_order:
        # get correct data subsets
        ind = df_exp[df_exp['data'] == dataset].index
        dfs_dataset_sel = [i.loc[ind] for i in dfs_dataset]
        # calcuate roc for pLDDT and scRMSD
        roc_plddt = [compute_roc_metrics(df_exp.loc[ind].monomeric.astype(int), vals.plddt.values) for vals in dfs_dataset_sel]
        roc_rmsd = [compute_roc_metrics(df_exp.loc[ind].monomeric.astype(int), -vals.rmsd.values) for vals in dfs_dataset_sel]
        # prepare plotting df
        dfs_roc.append(make_df_barplot(roc_plddt, roc_rmsd, nr=len(ind), name=dataset))
    df_out = add_weighted_avg(pd.concat(dfs_roc))
    return df_out

def plot_bar_metrics(df_plot:pd.DataFrame, metric:str='AUC pLDDT', 
                     legend:bool=True, outline:bool=False, palette:list=[]):
    '''
    Fig 3
    plot barplot figure with experimental data
    '''
    # plot figure
    if outline:
        sns.barplot(data=df_plot, x='name', y=metric, hue='annot', palette=palette, alpha=0.7, legend=legend, lw=1, ec='black')
    else:
        sns.barplot(data=df_plot, x='name', y=metric, hue='annot', palette=palette, alpha=0.7, legend=legend)
    plt.ylabel(metric, fontsize=30, labelpad=10)
    plt.xlabel('')
    plt.xticks(fontsize=22, rotation=15)
    plt.yticks(fontsize=22)
    sns.despine()
    plt.tight_layout()
    plt.ylim(0, 1.0)
    if legend:
        leg = plt.legend(bbox_to_anchor=(0, 1.1), loc='upper left', frameon=False, fontsize=22,edgecolor='white')
        for lh in leg.legend_handles: 
            lh.set_alpha(1)
    #plt.savefig(os.path.join(folder_outputs, name_out), bbox_inches='tight', dpi=300)
    #plt.show()

def plot_bar_metrics_overlap(df3:pd.DataFrame, df48:pd.DataFrame, metric:str, name_out:str, 
                             folder_outputs:str = '.', palette:list = ['#40498e','#A173CF','#357ba3'], legend=True):
    '''
    Fig 3 
    plot overlapping barplots for 3 and 48 recycles
    '''
    # plot figure overlapping 3 and 48 recycles
    plt.figure(figsize=(13, 6))
    palette = ['#40498e','#A173CF','#357ba3']
    plot_bar_metrics(df48, metric=metric, legend=False, palette=palette)
    plot_bar_metrics(df3, metric=metric, outline=True, legend=legend, palette=palette)
    plt.vlines(6.5,1,0, color='grey', linestyles='dashed')
    plt.hlines(0.5,-10,10, color='grey', linestyles='dashed', zorder=-1)
    plt.ylim(0, 1)
    plt.xlim(-0.5, 7.5)
    plt.ylabel(metric)
    plt.savefig(os.path.join(folder_outputs, name_out), bbox_inches='tight', dpi=300)
    plt.show()


def plot_length(df_in:pd.DataFrame, folder_outputs:str='.', name:str='out.png'):
    '''
    Fig 3
    Make boxplot of sequence length for each benchmark set
    '''
    plt.figure(figsize=(13, 6))
    fig, ax= plt.subplots(figsize=(13, 5))
    sns.boxplot(data=df_in, x='name', y='seqlength', hue='name', palette='Blues', ax=ax)
    plt.yticks(fontsize=22)
    ax.set_xticklabels(ax.get_xticklabels(), fontsize=22, rotation=15)
    plt.xlabel('')
    plt.ylabel('Seq length', fontsize=30)
    sns.despine()
    plt.tight_layout()
    plt.vlines(6.5,0,250, color='grey', linestyles='dashed')
    plt.ylim(0,250)
    plt.savefig(os.path.join(folder_outputs, name), bbox_inches='tight', dpi=300, transparent=True)
    plt.show()


def plot_Neff(df_in:pd.DataFrame, folder_outputs:str='.', name:str='out.png'):
    '''
    Fig 3
    Make barplot of Neff values for each benchmark set
    '''
    # plot figure
    plt.figure(figsize=(13, 6))
    fig, ax= plt.subplots(figsize=(13, 5))
    sns.barplot(data=df_in, x='name', y='Neff_medres', hue='name', palette='Blues', ax=ax, lw=1, ec='black')
    sns.stripplot(data=df_in, x="name", y="Neff_medres", size=4, color=".3")
    ax.set_yscale('log')
    #ax.fill_between(np.arange(-0.7,8, 0.01), 10,100, color='lightgrey', alpha=0.5, zorder=-1)
    ax.set_xlim(-0.6, 7.6)
    #ax.set_ylim(0, 200)
    ax.set_xticklabels(ax.get_xticklabels(), fontsize=22, rotation=15)
    plt.xlabel('')
    plt.ylabel('med. per-res Neff', fontsize=30)
    plt.yticks(fontsize=22)
    sns.despine()
    plt.tight_layout()
    plt.vlines(6.5,0,10000, color='grey', linestyles='dashed')
    #plt.hlines(50,-10,50, color='grey', linestyles='dashed', zorder=-1)
    plt.savefig(os.path.join(folder_outputs, name), bbox_inches='tight', dpi=300, transparent=True)
    plt.show()

# ==============================
# Fig 4 — Scope analysis
# ==============================

def add_secstr_pct(df_in):
    '''
    Fig 4
    calculate secondary structure percentages from dssp asignment
    '''
    df_out = df_in.copy()
    # add secondary structure content of native sequence
    df_out['helix_percentWT'] = [(np.array(list(i)) == 'H').astype(int).sum() / len(i) for i in df_out.dsspWT.values]
    df_out['strand_percentWT'] = [(np.array(list(i)) == 'E').astype(int).sum() / len(i) for i in df_out.dsspWT.values]
    df_out['coil_percentWT'] = [(np.array(list(i)) == 'C').astype(int).sum() / len(i) for i in df_out.dsspWT.values]
    # add secondary structure content of pMPNN sequence
    df_out['helix_percent'] = [(np.array(list(i)) == 'H').astype(int).sum() / len(i) for i in df_out.dssp.values]
    df_out['strand_percent'] = [(np.array(list(i)) == 'E').astype(int).sum() / len(i) for i in df_out.dssp.values]
    df_out['coil_percent'] = [(np.array(list(i)) == 'C').astype(int).sum() / len(i) for i in df_out.dssp.values]
    return df_out

def bucketize_scope_bylen(df_scope:pd.DataFrame, bins):
    '''
    Fig 4
    Takes as input the pd.DataFrame with the column 'length' and sorts each length into a bin
    Bins are by 50, starting from 50 ending with 500. Adds a bin for lengths > 500.
    '''
    bin_centers = 0.5 * (bins[:-1] + bins[1:])
    labels = [str(round(i)) for i in bin_centers]
    
    df_scope['length'] = df_scope['length'].astype(int)
    df_scope['length_bucket'] = pd.cut(df_scope['length'], bins=bins, labels=labels, right=False)
    return df_scope

def lineplot_bucketized_lens(meta:pd.DataFrame, figs:str, bins=np.arange(0, 501, 50), ax=' ', name='a', y='wt_designable'):
    '''
    Fig 4
    Plot average designability (WT vs pMPNN) across length buckets.
    '''
    #meta = bucketize_lens(meta, bins)
    meta = bucketize_scope_bylen(meta, bins)
    pal_blue   = sns.color_palette('Blues', 10).as_hex()
    pal_rocket = sns.color_palette('rocket_r', 10).as_hex()
    colors = ['#40498e', '#d92847', ]
    #colors = [pal_blue[5], pal_rocket[2]]
    color_mpnn = {'a':pal_rocket[0], 'b':pal_rocket[2], 'c':pal_rocket[4], 'd':pal_rocket[5], ' ':pal_rocket[2]}
    color_wt = {'a':pal_blue[2], 'b':pal_blue[4], 'c':pal_blue[6], 'd':pal_blue[8], ' ':pal_blue[5]}
    if 'wt' in y or 'WT' in y:
        type = 'wt'
    else:
        type = 'mpnn'
    if type == 'wt':
        sns.lineplot(x='length_bucket', y=y, data=meta, ax=ax, color=colors[0], #color=color_wt[name],
                     label=name+' native', linewidth=4, marker='o', markersize=10)
    if type == 'mpnn':
        sns.lineplot(x='length_bucket', y=y,    data=meta, ax=ax,color=colors[1], #color=color_mpnn[name],
                     label=name+' MPNN', linewidth=4, marker='o', markersize=10)

    # Nice axis formatting
    ax.set_xlabel('Length Bin', fontsize=29, labelpad=10)
    ax.set_ylabel('Designability', fontsize=29, labelpad=10)
    ax.tick_params(axis='both', which='major', labelsize=23)
    # Replace bucket labels with right edges (e.g., 50, 100, ...)
    ax.set_xticklabels([f'{bins[i+1]}' for i in range(len(bins)-1)])

def lineplots_lens_combined(meta:pd.DataFrame, metrics:list=[], folder_outputs:str='.', name:str='out.png'):
    '''
    Fig 4
    overlay lineplots of multiple metrics into one figure
    '''
    plt.clf()
    fig, ax = plt.subplots(figsize=(8, 5), constrained_layout=True)
    for metric in metrics:
        lineplot_bucketized_lens(meta, '.', ax=ax, name=' ', y=metric)
    if 'designable' in metrics or 'wt_designable' in metrics:
        ax.set_ylim(0, 0.85)
        ax.set_ylabel('Designability')
    if 'rmsd' in metrics or 'rmsdWT' in metrics:
        plt.hlines(2,-1,10, linestyles='dashed', color='lightgrey', zorder=-1)
        ax.set_ylim(0, 25)
        ax.set_xlim(-0.2,9.2)
        ax.set_ylabel('scRMSD')
    if 'plddt' in metrics or 'plddtWT' in metrics:
        plt.hlines(70,-1,10, linestyles='dashed', color='lightgrey', zorder=-1)
        ax.set_ylim(30, 90)
        ax.set_xlim(-0.2,9.2)
        ax.set_ylabel('pLDDT')
    plt.savefig(os.path.join(folder_outputs, name), dpi=300, bbox_inches='tight')
    plt.show()

def pick_n_proteins(df:pd.DataFrame, n:int):
    '''
    Fig 4
    Picks n proteins from each length bin considering the seed.
    ''' 
    seed = np.random.seed(123)
    n_proteins = []
    for i in df['length_bucket'].unique():
        proteins_in_bin = df[df['length_bucket'] == i]
        if len(proteins_in_bin) > n:
            selected_proteins = proteins_in_bin.sample(n=n, random_state=seed)
        else:
            selected_proteins = proteins_in_bin
        n_proteins.append(selected_proteins)
    return pd.concat(n_proteins)

def get_flat_dist(meta:pd.DataFrame, bins, class_sel='abcd', verbose=False):
    '''
    Fig 4
    given a dataframe with entries and a column with SCOPe classes,
    select the largest possible flat distribution that can be selected 
    for that class based the bins provided. 
    '''
    bucketized_scope_df = bucketize_scope_bylen(meta, bins=bins)

    index_out = []
    for i in class_sel:
        data = bucketized_scope_df[bucketized_scope_df.scop_class == i]
        N = 1
        while True:
            sel = pick_n_proteins(data, N)
            c, b = np.histogram(sel.length.values, bins= bins)
            if np.all(c == N):
                N+=1
                continue
            else:
                sel = pick_n_proteins(data, N-1)
                if verbose:
                    print(i, N-1)
                break
        if verbose:
            print(N*(len(bins)-1))    
            plt.hist(sel.length.values, bins=bins)
            plt.show()
        index_out+=list(sel.index.values)
    return index_out

def barplot_fold_des(meta:pd.DataFrame, folder_outputs:str='.', name:str='out.png', 
                     bootstrap:bool=True, n_boots:int=100, col:str='designable'):
    '''
    Fig 4
    Barplot of designability per SCOPe class, optionally with bootstrap mean/std.
    '''
    palette = sns.color_palette('rocket_r', 8).as_hex()
    classes = sorted(meta['scop_class'].unique())

    if bootstrap:
        rng = np.random.default_rng(123)
        boot_vals = {cls: [] for cls in classes}
        for i in range(n_boots):
            sample = meta.sample(frac=1, replace=True, random_state=int(rng.integers(0, 1e9)))
            grouped = sample.groupby('scop_class')[col].mean()
            for cls in classes:
                boot_vals[cls].append(grouped.get(cls, np.nan))
        mean_des = pd.Series({cls: np.nanmean(vals) for cls, vals in boot_vals.items()})
        std_des  = pd.Series({cls: np.nanstd(vals, ddof=1) for cls, vals in boot_vals.items()})
    else:
        grouped = meta.groupby('scop_class')[col]
        mean_des = grouped.mean()
        std_des  = grouped.std(ddof=1)

    fig, ax = plt.subplots(figsize=(6, 5), constrained_layout=True)

    if col == 'designable':
        palette = palette[0:len(mean_des.index)]
    else:
        palette = 'Blues'
    sns.barplot(x=mean_des.index, y=mean_des.values, palette=palette, ax=ax, width=.7, hue=mean_des.index)

    # Overlay error bars
    ax.errorbar(x=np.arange(len(mean_des)), y=mean_des.values, yerr=std_des.values,
                fmt='none', c='black', capsize=5, elinewidth=2.0)

    ax.set_ylabel('Designability', fontsize=29, labelpad=10)
    ax.set_xlabel('SCOPe class', fontsize=29, labelpad=10)
    ax.set_ylim(0, 0.55)
    ax.tick_params(axis='both', labelsize=23)
    ax.set_xticklabels(mean_des.index, rotation=0)
    fig.savefig(os.path.join(folder_outputs, name), dpi=300, bbox_inches='tight')
    plt.show()

def flatten_stat(df, stat='mean'):
    '''
    Fig 4
    Take df and flatten stat
    '''
    out = df.loc[:, (slice(None), stat)]
    out.columns = [c[0] for c in out.columns]
    return out

def to_long_df(means_df, stds_df, label):
    '''
    Fig 4
    convert to long df
    '''
    df = means_df.copy()
    df['Designability'] = label
    df = df.reset_index(drop=True)
    df = df.melt(id_vars='Designability', var_name='Secondary Structure', value_name='Mean')
    stds = stds_df.reset_index(drop=True).melt(var_name='Secondary Structure', value_name='Std')
    df['Std'] = stds['Std'].values
    return df

def make_df_bar_secstruct(df_undesignable, df_designable):
    '''
    Fig 4
    prepare df for barplot plotting secondary structure percentages
    '''
    # calculate statistics on designable and undesignable set
    undesignable_sec_struct = df_undesignable.groupby('wt_designable')[['helix_percentWT','strand_percentWT','coil_percentWT']].describe()
    designable_sec_struct   = df_designable  .groupby('wt_designable')[['helix_percentWT','strand_percentWT','coil_percentWT']].describe()
    sec_struct_all = pd.concat([designable_sec_struct, undesignable_sec_struct]).reset_index()
    # select statistics
    und_means = flatten_stat(undesignable_sec_struct, 'mean')
    und_stds  = flatten_stat(undesignable_sec_struct, 'std')
    des_means = flatten_stat(designable_sec_struct, 'mean')
    des_stds  = flatten_stat(designable_sec_struct, 'std')
    all_means = flatten_stat(sec_struct_all, 'mean')
    all_stds  = flatten_stat(sec_struct_all, 'std')
    # combine statistics into one df
    plot_df = pd.concat([to_long_df(des_means, des_stds, 'Designable'),
                         to_long_df(und_means, und_stds, 'Undesignable'),
                         to_long_df(all_means, all_stds, 'All'),], ignore_index=True)
    return plot_df

def bar_des_undes_secstruct(plot_df: pd.DataFrame, folder_outputs:str='.', name:str='out.png'):
    '''
    Fig 4
    Barplot of secondary structure composition by designability label.
    '''
    palette = {
        'Designable':   sns.color_palette('Blues', 4)[2],
        'Undesignable': sns.color_palette('Greys', 4)[2],
        'All':          sns.color_palette('Purples', 4)[1]}
    fig, ax = plt.subplots(figsize=(6, 5), constrained_layout=True)
    sns.barplot(data=plot_df, x='Secondary Structure', y='Mean', hue='Designability',
                palette=palette, ax=ax, errorbar=None)
    ax.set_ylim(0, 1.0)
    ax.set_ylabel('Percentage', fontsize=29, labelpad=10)
    ax.set_xlabel('Secondary Structure', fontsize=29, labelpad=10)
    ax.tick_params(axis='both', labelsize=23)
    ax.set_xticklabels(['Helix', 'Strand', 'Coil'])
    ax.legend(title='', fontsize=20, frameon=False)
    fig.savefig(os.path.join(folder_outputs, name), dpi=300, bbox_inches='tight')
    plt.show()

# ==============================
# Fig 5 — Flexible regions
# ==============================

def plot_paramspace_att(df_pdb:pd.DataFrame, df_afdb:pd.DataFrame, df_att:pd.DataFrame,
                                     folder_outputs:str='.', name:str='out.png'):
    '''
    Fig 5
    Plot changes in parameter space (pLDDT, scRMSD) for the attenuation experiment
    '''
    plt.figure(figsize=(8,8))
    names = ['PDB', 'AFDB-full', 'AFDB-att']
    palette = sns.color_palette('rocket_r', 6).as_hex()[2:]
    # plot line connecting full AFDB with attenuated AFDB
    plt.plot([df_afdb.rmsd.values.mean(), df_att.rmsd.values.mean()], [df_afdb.plddt.values.mean(), df_att.plddt.values.mean()], 
             color=palette[1], zorder=-1, alpha=0.9)
    # plot the points themselves
    for i, data in enumerate([df_pdb, df_afdb, df_att]):
        plt.scatter(data.rmsd.values.mean(), data.plddt.values.mean(), color=palette[i], alpha=1, s=450, label=names[i], lw=1, ec='black')
        #plt.errorbar(data.wrmsd.values.mean(), data.plddt.values.mean(), yerr=sem(data.plddt.values), xerr=sem(data.wrmsd.values), color='black')
        #plt.errorbar(data.rmsd.values.mean(), data.plddt.values.mean(), yerr=sem(data.plddt.values), xerr=sem(data.rmsd.values), color='black')
    plt.xlim(0,4)
    plt.ylim(60,100)
    plt.hlines(70,0,2, linestyle='dashed', color='lightgrey')
    plt.vlines(2,70,100, linestyle='dashed', color='lightgrey')
    plt.xticks(fontsize=24)
    plt.yticks(fontsize=24)
    plt.ylabel('pLDDT', fontsize=24)
    plt.xlabel('scRMSD (Å)', fontsize=24)
    sns.despine()
    plt.savefig(os.path.join(folder_outputs, name), dpi=300, bbox_inches='tight')
    plt.show()

def make_df_realignment(df_list:list[pd.DataFrame], df_names:list, order_cols:list):
    '''
    Fig 5
    Pepare dataframe for plotting the designability of various (re)alignment methods
    '''
    label = {'designable':'Kabsch', 'designable_tm':'TMalign', 'designable_rmsd_out':'Kabsch w/o outliers', 
         'designable_sheba':'Sheba', 'designable_w':'Kabsch realign w/o outliers',
         'designable_m':'Kabsch', 'designable_tm_m':'TMalign', 'designable_rmsd_out_m':'Kabsch w/o outliers', 
         'designable_sheba_m':'Sheba', 'designable_w_m':'Kabsch realign w/o outliers'}
    designable_vals, type, method = [], [], []
    for col in order_cols:
        for n, df in zip(df_names, df_list):
            designable_vals.extend(df[col].values.astype(int))
            type.extend(len(df)*[n])
            method.extend(len(df)*[label[col]])
    df_out = pd.DataFrame({'Designable':designable_vals, 'type':type, 'method':method})
    return df_out

def plot_bar_realignment(df_mean:pd.DataFrame, df_median:pd.DataFrame, folder_outputs:str='.', name:str='out.png'):
    '''
    Fig 5
    plot barplot with the designability for different (re)alignment methods
    '''
    plt.figure(figsize=(8,8))
    ax = sns.barplot(data=df_mean, x='type', y='Designable', hue='method', 
                     palette='rocket', legend=False, alpha=0.7, capsize=0.1)
    sns.barplot(data=df_median, x='type', y='Designable', hue='method', 
                palette='rocket', alpha=0.5, lw=1.5, ec='black', ax=ax, capsize=0.1)
    sns.despine()
    plt.tight_layout()
    plt.xlabel(' ')
    plt.xticks(fontsize=22)
    plt.yticks(fontsize=22) # for vert change rotation
    plt.ylabel('Designability',fontsize=30)
    plt.ylim(0.5, 1) # for vert change y to x
    leg = plt.legend(bbox_to_anchor=(1, 1.1))
    
    for lh in leg.legend_handles: 
        lh.set_alpha(0.8)
    plt.savefig(os.path.join(folder_outputs, name), dpi=300, bbox_inches='tight')
    plt.show()

def plot_bars_designability(df_in:pd.DataFrame, metric:str, folder_outputs:str='.', name:str='out.png'):
    '''
    Fig 5
    Plot barplots with the designablity of different datasets
    '''
    palette = sns.color_palette('rocket_r', 6).as_hex()[2:-1]
    plt.figure(figsize=(8,8))
    sns.barplot(data=df_in, x='type', y=metric, hue='type', palette=palette, alpha=0.9, capsize=0.1)
    sns.despine()
    plt.tight_layout()
    plt.ylim(0.5, 1)
    plt.xlabel(' ')
    plt.xticks(fontsize=24)
    plt.yticks(fontsize=24)
    plt.ylabel('Designability',fontsize=30)
    plt.savefig(os.path.join(folder_outputs, name), dpi=300, bbox_inches='tight')
    plt.show()

def plot_bars_designability_overlap(df_in:pd.DataFrame, metrics:list, folder_outputs:str='.', name:str='out.png'):
    '''
    Fig 5
    Plot overlapping barplots with the designability before and after realignment
    '''   
    palette = sns.color_palette('rocket_r', 6).as_hex()[2:-1]
    plt.figure(figsize=(8,8))
    ax = sns.barplot(data=df_in, x='type', y=metrics[0], hue='type', palette=palette, alpha=0.7, capsize=0.1, legend=False)
    sns.barplot(data=df_in, x='type', y=metrics[1], hue='type', palette=palette,  alpha=0.7, ax=ax, lw=1.9, ec='black', capsize=0.1, legend=False)
    sns.despine()
    plt.tight_layout()
    plt.ylim(0.5, 1)
    plt.xlabel(' ')
    plt.xticks(fontsize=24)
    plt.yticks(fontsize=24)
    plt.ylabel('Designability',fontsize=30)
    plt.savefig(os.path.join(folder_outputs, name), dpi=300, bbox_inches='tight')
    plt.show()

# ==============================
# Fig S3 — Soluprot designability
# ==============================

def match_selection(dist_1, dist_2, bins=10):
    '''
    Fig S3
    Function used to match the length distribution between the soluble and insoluble entries
    given two distributions of data dist_1 and dist_2, 
    where len(dist_1) << len(dist_2), return a list of indices for dist_2 
    that matches the shape of dist_1 for a given bin count. 
    '''
    # bin data using the same bins
    c1,b1 = np.histogram(dist_1, bins=bins)
    c2,b2 = np.histogram(dist_2, bins=b1)
    # check how many N times dist_1 fits in dist_2
    N=0
    while np.all(c1*N <= c2):
        print(N)
        N+=1
    c_out = c1*N
    b_out = b1
    # get right ind for dist2
    selection_bins = []
    lastbin = b_out[0]
    # randomly select N * dist_1 data points from dist_2 
    for nr, bn in zip(c_out, b_out[1:]):
        if nr == 0:
            lastbin = bn
            continue
        print(lastbin, bn)
        bin_sel = np.where(np.logical_and(dist_2 > lastbin, dist_2 < bn))[0]
        print(nr, len(bin_sel))
        if int(nr) > len(bin_sel):
            size = len(bin_sel)
        else:
            size = nr

        bin_sel = np.random.choice(bin_sel, size=size, replace=False)
        selection_bins+=list(bin_sel)
        lastbin = bn
    print(sum(c_out))
    return selection_bins

def plot_violin_soluprot_rmsd(df, name_out='out.png'):
    '''
    plot a violin plot for scRMSD for the solubility data
    '''
    palette = ['#f47d57', '#a1cbe2']
    # Ensure the relevant columns are numeric (in case of missing/empty values)
    df['rmsd_msa'] = pd.to_numeric(df['rmsd_msa'], errors='coerce')
    df['rmsd_ss'] = pd.to_numeric(df['rmsd_ss'], errors='coerce')
    df['solubility'] = pd.to_numeric(df['solubility'], errors='coerce')
    # Filter out rows with missing values in the relevant columns
    msa_valid = df.dropna(subset=['rmsd_msa', 'solubility'])
    ss_valid = df.dropna(subset=['rmsd_ss', 'solubility'])
    esmf_valid = df.dropna(subset=['rmsd_esmf', 'solubility'])
    # Prepare data for combined violin plot
    msa_plot = msa_valid[['rmsd_msa', 'solubility']].copy()
    msa_plot = msa_plot.rename(columns={'rmsd_msa': 'RMSD', 'solubility': 'Solubility'})
    msa_plot['Type'] = 'MSA'
    ss_plot = ss_valid[['rmsd_ss', 'solubility']].copy()
    ss_plot = ss_plot.rename(columns={'rmsd_ss': 'RMSD', 'solubility': 'Solubility'})
    ss_plot['Type'] = 'SS'
    esmf_plot = esmf_valid[['rmsd_esmf', 'solubility']].copy()
    esmf_plot = esmf_plot.rename(columns={'rmsd_esmf': 'RMSD', 'solubility': 'Solubility'})
    esmf_plot['Type'] = 'ESMF'
    # Map solubility to string for better legend labels
    plot_df = pd.concat([ss_plot, esmf_plot, msa_plot], ignore_index=True) 
    plot_df['Solubility'] = plot_df['Solubility'].map({0: 'Insoluble (0)', 1: 'Soluble (1)'})
    # plot data
    plt.figure(figsize=(7, 6))
    # Remove default inner representation to avoid double plotting
    ax = sns.violinplot(data=plot_df, x='Type', y='RMSD', hue='Solubility', palette=palette,
                        split=True, fill=False, legend=False, inner=None ) 
    # Overlay individual data points (less prominent, e.g., small, alpha<1)
    sns.stripplot(data=plot_df, x='Type', y='RMSD', hue='Solubility', palette=palette, ax=ax,
                  dodge=True, jitter=True, size=2, alpha=0.5, linewidth=0, legend=False)
    # Get unique types and solubility classes
    types = plot_df['Type'].unique()
    solubilities = plot_df['Solubility'].unique()
    # Get the positions of the violins as used by seaborn
    # For split violins, the positions are at 0, 1, ... for each 'Type'
    # We'll offset slightly for each 'Solubility' within each 'Type'
    for i, t in enumerate(types):
        for j, s in enumerate(solubilities):
            group = plot_df[(plot_df['Type'] == t) & (plot_df['Solubility'] == s)]
            if not group.empty:
                mean_val = group['RMSD'].median()
                # For split violins, the offset is -0.2 for left, +0.2 for right
                offset = -0.2 if j == 0 else 0.2
                # make the line a bit shorter than the violin width
                ax.hlines(mean_val, i + offset - 0.08,  i + offset + 0.08,
                          colors='k', linewidth=2, zorder=10)
    plt.xlabel(' ')
    plt.ylabel('scRMSD [Å]', fontsize=24)
    plt.xticks(fontsize=22)
    plt.yticks(fontsize=22)   
    plt.ylim(-2,40)
    plt.xlim(-0.5,2.5)
    plt.hlines(2, -1, 3, linestyle='dashed', color='lightgrey')
    # Remove duplicate legends from stripplot
    handles, labels = plt.gca().get_legend_handles_labels()
    # Only keep the first two (for hue), since both plots add legend entries
    n = len(plot_df['Solubility'].unique())
    #plt.legend(handles[:n], labels[:n], title='Solubility')
    plt.tight_layout()
    plt.savefig(name_out, dpi=300, bbox_inches='tight')
    plt.show()

def plot_violin_soluprot_plddt(df, name_out='out.png'):
    '''
    plot a violin plot for pLDDT for the solubility data
    '''
    palette = ['#f47d57', '#a1cbe2']
    # Ensure the relevant columns are numeric (in case of missing/empty values)
    df['plddt_msa'] = pd.to_numeric(df['plddt_msa'], errors='coerce')
    df['plddt_ss'] = pd.to_numeric(df['plddt_ss'], errors='coerce')
    df['solubility'] = pd.to_numeric(df['solubility'], errors='coerce')
    # Filter out rows with missing values in the relevant columns
    msa_valid = df.dropna(subset=['plddt_msa', 'solubility'])
    ss_valid = df.dropna(subset=['plddt_ss', 'solubility'])
    esmf_valid = df.dropna(subset=['plddt_esmf', 'solubility'])
    # Prepare data for combined violin plot
    msa_plot = msa_valid[['plddt_msa', 'solubility']].copy()
    msa_plot = msa_plot.rename(columns={'plddt_msa': 'pLDDT', 'solubility': 'Solubility'})
    msa_plot['Type'] = 'MSA'
    ss_plot = ss_valid[['plddt_ss', 'solubility']].copy()
    ss_plot = ss_plot.rename(columns={'plddt_ss': 'pLDDT', 'solubility': 'Solubility'})
    ss_plot['Type'] = 'SS'
    esmf_plot = esmf_valid[['plddt_esmf', 'solubility']].copy()
    esmf_plot = esmf_plot.rename(columns={'plddt_esmf': 'pLDDT', 'solubility': 'Solubility'})
    esmf_plot['Type'] = 'ESMF'
    # Map solubility to string for better legend labels
    plot_df = pd.concat([ss_plot, esmf_plot, msa_plot], ignore_index=True)
    plot_df['Solubility'] = plot_df['Solubility'].map({0: 'Insoluble (0)', 1: 'Soluble (1)'})
    plt.figure(figsize=(7, 6))
    # Remove default inner representation to avoid double plotting
    ax = sns.violinplot(data=plot_df, x='Type', y='pLDDT', hue='Solubility', palette=palette,
                        split=True,fill=False,legend=False,inner=None )
    # Overlay individual data points (less prominent, e.g., small, alpha<1)
    sns.stripplot(data=plot_df, x='Type', y='pLDDT', hue='Solubility', palette=palette, ax=ax,
                  dodge=True,jitter=True,size=2, alpha=0.5, linewidth=0, legend=False)
    # Get unique types and solubility classes
    types = plot_df['Type'].unique()
    solubilities = plot_df['Solubility'].unique()
    # Get the positions of the violins as used by seaborn
    # For split violins, the positions are at 0, 1, ... for each 'Type'
    # We'll offset slightly for each 'Solubility' within each 'Type'
    for i, t in enumerate(types):
        for j, s in enumerate(solubilities):
            group = plot_df[(plot_df['Type'] == t) & (plot_df['Solubility'] == s)]
            if not group.empty:
                mean_val = group['pLDDT'].median()
                # For split violins, the offset is -0.2 for left, +0.2 for right
                offset = -0.2 if j == 0 else 0.2
                # make the line a bit shorter than the violin width
                ax.hlines(mean_val, i + offset - 0.08, i + offset + 0.08, 
                          colors='k', linewidth=2, zorder=10 )
    #plt.title('Violin plot of RMSD by Type and Solubility')
    plt.xlabel(' ')
    plt.ylabel('pLDDT', fontsize=24)
    plt.xticks(fontsize=22)
    plt.yticks(fontsize=22)
    #plt.ylim(-2,40)
    plt.xlim(-0.5,2.5)
    plt.hlines(70, -1, 3, linestyle='dashed', color='lightgrey')
    # Remove duplicate legends from stripplot
    handles, labels = plt.gca().get_legend_handles_labels()
    # Only keep the first two (for hue), since both plots add legend entries
    n = len(plot_df['Solubility'].unique())
    #plt.legend(handles[:n], labels[:n], title='Solubility')
    plt.tight_layout()
    plt.savefig(name_out, dpi=300, bbox_inches='tight')
    plt.show()

def plot_bars_soluprot_des(df, name_out='out.png'):
    '''
    plot a bar plot for designability of the solubility data
    '''
    palette = ['#f47d57', '#a1cbe2']
    df['designability_ss'] = ((df.plddt_ss.values >= 70) & (df.rmsd_ss.values <= 2))
    df['designability_msa'] = ((df.plddt_msa.values >= 70) & (df.rmsd_msa.values <= 2))
    df['designability_esmf'] = ((df.plddt_esmf.values >= 70) & (df.rmsd_esmf.values <= 2))
    # Filter out rows with missing values in the relevant columns
    msa_valid = df.dropna(subset=['plddt_msa', 'rmsd_msa', 'solubility'])
    ss_valid = df.dropna(subset=['plddt_ss', 'rmsd_ss', 'solubility'])
    esmf_valid = df.dropna(subset=['plddt_esmf', 'rmsd_esmf','solubility'])
    # Prepare data for combined violin plot
    msa_plot = msa_valid[['designability_msa', 'solubility']].copy()
    msa_plot = msa_plot.rename(columns={'designability_msa': 'Designability', 'solubility': 'Solubility'})
    msa_plot['Type'] = 'MSA'
    ss_plot = ss_valid[['designability_ss', 'solubility']].copy()
    ss_plot = ss_plot.rename(columns={'designability_ss': 'Designability', 'solubility': 'Solubility'})
    ss_plot['Type'] = 'SS'
    esmf_plot = esmf_valid[['designability_esmf', 'solubility']].copy()
    esmf_plot = esmf_plot.rename(columns={'designability_esmf': 'Designability', 'solubility': 'Solubility'})
    esmf_plot['Type'] = 'ESMF'
    # Map solubility to string for better legend labels
    plot_df = pd.concat([ss_plot, esmf_plot, msa_plot], ignore_index=True)
    plot_df['Solubility'] = plot_df['Solubility'].map({0: 'Insoluble (0)', 1: 'Soluble (1)'})
    # plot significance ushing fisher's exact test
    for method in [ 'SS', 'ESMF','MSA']:
        insol_des = len(plot_df[(plot_df.Solubility == 'Insoluble (0)') & (plot_df.Designability) & (plot_df.Type == method)])
        insol_indes = len(plot_df[(plot_df.Solubility == 'Insoluble (0)') & (~plot_df.Designability) & (plot_df.Type == method)])
        sol_des = len(plot_df[(plot_df.Solubility == 'Soluble (1)') & (plot_df.Designability) & (plot_df.Type == method)])
        sol_indes = len(plot_df[(plot_df.Solubility == 'Soluble (1)') & (~plot_df.Designability) & (plot_df.Type == method)])
        #print(insol_des/(insol_indes+insol_des), sol_des/(sol_indes+sol_des))
        matrix = [[insol_des,sol_des],[insol_indes, sol_indes]]
        print(method, fisher_exact(matrix))
    plt.figure(figsize=(7, 6))
    ax = sns.barplot(data=plot_df, x='Type', y='Designability', palette=palette, hue='Solubility',
                     legend=False, errorbar='se', capsize=0.1 )
    #plt.title('Violin plot of RMSD by Type and Solubility')
    plt.xlabel(' ')
    plt.ylabel('Designability', fontsize=24)
    plt.xticks(fontsize=22)
    plt.yticks(fontsize=22)
    plt.ylim(0,1)
    plt.xlim(-0.5,2.5)
    plt.tight_layout()
    plt.savefig(name_out, dpi=300, bbox_inches='tight')
    plt.show()
    
def plot_violin_soluprot_nopdb(plot_df, name_out='out.png'):
    palette = ['#f47d57', '#a1cbe2']
    plt.figure(figsize=(7, 6))
    ax = sns.violinplot(data=plot_df, x='type', y='pLDDT', hue='Solubility',palette=palette, 
                        split=True, fill=False, legend=False,inner=None)
    sns.stripplot(data=plot_df, x='type', y='pLDDT', hue='Solubility', palette=palette, ax=ax,
        dodge=True, jitter=True, size=2, alpha=0.5, linewidth=0, legend=False)
    # Get unique types and solubility classes
    types = plot_df['type'].unique()
    solubilities = plot_df['Solubility'].unique()
    for i, t in enumerate(types):
        for j, s in enumerate(solubilities):
            group = plot_df[(plot_df['type'] == t) & (plot_df['Solubility'] == s)]
            if not group.empty:
                mean_val = group['pLDDT'].median()
                # For split violins, the offset is -0.2 for left, +0.2 for right
                offset = -0.2 if j == 0 else 0.2
                ax.hlines(mean_val, i + offset - 0.08, i + offset + 0.08,
                          colors='k', linewidth=2, zorder=10 )
    #plt.title('Violin plot of RMSD by Type and Solubility')
    plt.xlabel(' ')
    plt.ylabel('pLDDT', fontsize=24)
    plt.xticks(fontsize=22)
    plt.yticks(fontsize=22)
    #plt.ylim(-2,40)
    plt.xlim(-0.5,2.5)
    plt.hlines(70, -1, 3, linestyle='dashed', color='lightgrey')
    # Remove duplicate legends from stripplot
    handles, labels = plt.gca().get_legend_handles_labels()
    # Only keep the first two (for hue), since both plots add legend entries
    n = len(plot_df['Solubility'].unique())
    #plt.legend(handles[:n], labels[:n], title='Solubility')

    plt.tight_layout()
    plt.savefig(name_out, dpi=300, bbox_inches='tight')

# ==============================
# Fig S6-8 — Optimal Thresholds
# ==============================

def compute_conf_metrics (true_vals, plddt_vals, rmsd_vals, name, rmsd_cutoff=2, plddt_cutoff=80):
    vals_pred = ((rmsd_vals <= rmsd_cutoff) & (plddt_vals >= plddt_cutoff))
    with warnings.catch_warnings():
        warnings.filterwarnings("ignore", message="Precision is ill-defined")
        #accuracy = metrics.accuracy_score(true_vals, vals_pred) 
        precision = metrics.precision_score(true_vals, vals_pred)
        f1 = metrics.f1_score(true_vals, vals_pred)
        rec = metrics.recall_score(true_vals, vals_pred)
    return precision, f1, rec

def get_maxscore(true_vals, df_vals, rmsd_range, plddt_range, metric='f1', returnmax=False):
    rmsds, plddts = np.meshgrid(rmsd_range, plddt_range)
    prec_out, acc_out, f1_out, rec_out = [], [], [], []
    for rmsd,plddt in zip(rmsds.flatten(), plddts.flatten()):
        vals = compute_conf_metrics(true_vals, df_vals.plddt.values, df_vals.rmsd.values,
                                    name=' ', rmsd_cutoff=rmsd, plddt_cutoff=plddt)
        prec_out.append(vals[0])
        f1_out.append(vals[1])
        rec_out.append(vals[2])
    rec_array_shaped = np.array(rec_out).reshape((len(plddt_range), len(rmsd_range)))
    if metric == 'f1':
        array_in = f1_out
    elif metric == 'acc':
        array_in = acc_out
    elif metric == 'prec':
        array_in = prec_out
    array_shaped = np.array(array_in).reshape((len(plddt_range), len(rmsd_range)))[::-1,::]
    #print(array_shaped)
    annot_array = array_shaped.copy()
    annot_array[rec_array_shaped[::-1,::] == 0] = 0
    max_idx = np.unravel_index(np.argmax(annot_array), array_shaped.shape)
    var = len(np.where(annot_array == np.max(annot_array))[0])
    #print(np.max(annot_array))
    if returnmax:
        return plddts[::-1,::][max_idx], rmsds[::-1,::][max_idx], np.max(annot_array), var
    else:
        return plddts[::-1,::][max_idx], rmsds[::-1,::][max_idx]


def optimize_cutoff(df_in, df_exp, order, metric='f1',
                    rmsd_range=np.arange(0.5,5.5, 0.5), plddt_range=np.arange(50, 105, 5)):
    '''
    return optimal cutoffs and corresponding scores
    '''
    x_vals, y_vals, score = [], [], []
    for n in order:
        df_sel = df_in[df_in.data == n]
        best = get_maxscore(df_exp.loc[df_sel.index].monomeric.values, df_sel, rmsd_range, plddt_range, metric=metric, returnmax=True)
        if best[-1] < 3:
            #print(best_ss[-1])
            x_vals.append(best[0])
            y_vals.append(best[1])
        score.append(best[2])
    return x_vals, y_vals, score


def heatmap_metric(true_vals, df_vals, rmsd_range, plddt_range):
    '''
    calculate precision, F1 and recall for a given set of true vals 
    and a df with matching plddt and rmsd scores
    '''
    rmsds, plddts = np.meshgrid(rmsd_range, plddt_range)
    prec_out, acc_out, f1_out, rec_out = [], [], [], []
    for rmsd,plddt in zip(rmsds.flatten(), plddts.flatten()):
        vals = compute_conf_metrics(true_vals, df_vals.plddt.values, df_vals.rmsd.values,
                                    name=' ', rmsd_cutoff=rmsd, plddt_cutoff=plddt)
        prec_out.append(vals[0])
        #acc_out.append(vals[1])
        f1_out.append(vals[1])
        rec_out.append(vals[2])
    return np.array(prec_out), np.array(f1_out), np.array(rec_out)

def plot_heatmap(array_in, rec_array_in, cutoff1_range, cutoff2_range, vmin=0, vmax=1):
    '''
    plot a heatmap for a given array of values, a recall array to block out if 0, 
    and a matching x and y range of cutoffs
    '''
    array_shaped = np.array(array_in).reshape((len(cutoff1_range), len(cutoff2_range)))
    rec_array_shaped = np.array(rec_array_in).reshape((len(cutoff1_range), len(cutoff2_range)))
    df_array = pd.DataFrame(
        data=array_shaped,
        columns=np.round(cutoff2_range, 1),
        index=np.round(cutoff1_range, 1))
    fig, ax = plt.subplots()
    sns.heatmap(df_array, vmin=vmin, vmax=vmax, fmt="", 
                cbar=True, cmap="coolwarm", ax=ax, center=0)

    # Overlay hatching manually for recall==0 cells
    for i, y in enumerate(df_array.index):
        for j, x in enumerate(df_array.columns):
            if rec_array_shaped[i, j] == 0:
                rect = Rectangle((j, i), 1, 1, 
                                 facecolor="none", edgecolor="black",
                                 hatch="///", linewidth=0)
                ax.add_patch(rect)
    plt.yticks([])
    plt.xticks([])

def make_confusion_matrix(true_values, predicted_values, name_out='fig-out.png'):
    '''
    plt a confusion matrix for a given set of true values and predicted values
    '''
    cfm = metrics.confusion_matrix(true_values, predicted_values)
    ax = sns.heatmap(cfm[::-1,::-1], cmap='Blues', annot=True, cbar=False, annot_kws={"fontsize":20},
                      xticklabels=['True', 'False'], 
                      yticklabels=['True', 'False '], vmin=0, vmax=50)
    plt.ylabel('True outcome', fontsize=20, labelpad=10)
    plt.xlabel('Predicted outcome', fontsize=20, labelpad=10)
    plt.tick_params(top=True, bottom=False, labeltop=True, labelbottom=False)
    ax.xaxis.set_label_position('top')
    plt.savefig(name_out, bbox_inches="tight", dpi=300)
    plt.show()